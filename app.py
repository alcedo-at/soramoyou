import os
import glob
import numpy as np
from PIL import Image
import torch
import clip
from sklearn.metrics.pairwise import cosine_similarity
from google import genai
from google.genai.types import Part
from dotenv import load_dotenv
import pillow_heif
import streamlit as st

# ======== åˆæœŸè¨­å®š ========
pillow_heif.register_heif_opener()
load_dotenv()

api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    st.error("ç’°å¢ƒå¤‰æ•° GEMINI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

client = genai.Client(api_key=api_key)
model_id = "gemini-2.0-flash-exp"

# CLIPãƒ¢ãƒ‡ãƒ«ã®æº–å‚™
def load_clip_model():
    device = "cpu"  # Cloudä¸Šã§ã¯å¸¸ã«CPU
    model, preprocess = clip.load("ViT-B/32", device=device)
    return model, preprocess

# ======== é–¢æ•°å®šç¾© ========

def describe_image_with_gemini(client, image_bytes):
    """Geminiã§ç©ºã‚’è¡¨ã™æ—¥æœ¬èªã¨æ“¬æ…‹èªã‚’ç”Ÿæˆ"""
    try:
        response = client.models.generate_content(
            model=model_id,
            contents=[
                """æ¬¡ã®å†™çœŸã‹ã‚‰ç©ºã‚’è¡¨ã™æ—¥æœ¬èªã¨æ“¬æ…‹èªã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
                 çµ¶å¯¾ã«ã€Œã¯ã„ã€æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€ãªã©ã®å®šå‹æ–‡ã¯è¿”ã•ãªã„ã§ãã ã•ã„ã€‚
ä¾‹ï¼š
ç©ºã‚’è¡¨ã™æ—¥æœ¬èªï¼šå¿«æ™´ã€é›²å±…ã®ç©ºã€é’åµã€é›²ã®å ¤  
æ“¬æ…‹èªï¼šãµã‚ãµã‚ã€ã‚¹ã‚«ãƒƒã¨ã€ã‚‚ãµã‚‚ãµã€ã™ãƒ¼ã£  

ã¾ãŸã€ç©ºã‚’è¡¨ã™æ—¥æœ¬èªã¯è¾æ›¸çš„ãªå®šç¾©ã‚‚å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚""",
                Part.from_bytes(data=image_bytes, mime_type="image/jpeg")
            ],
        )
        text = getattr(response, "text", None)
        if not text:
            try:
                text = response.candidates[0].content.parts[0].text
            except Exception:
                text = str(response)
        return text
    except Exception as e:
        return f"APIå‘¼ã³å‡ºã—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸï¼š{e}"

def get_image_feature(image_path_or_file):
    """CLIPã§ç”»åƒç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã‚’æŠ½å‡ºï¼ˆHEICå¯¾å¿œãƒ»æ­£è¦åŒ–ä»˜ãï¼‰"""
    if isinstance(image_path_or_file, str):
        image = Image.open(image_path_or_file)
    else:
        image = Image.open(image_path_or_file)
    image = image.convert("RGB").resize((512, 512))
    image_input = preprocess(image).unsqueeze(0).to(device)

    with torch.no_grad():
        feature = clip_model.encode_image(image_input)
    feature /= feature.norm(dim=-1, keepdim=True)
    return feature.cpu().numpy()[0]

def find_top_similar(query_feature, features_dict, top_k=3):
    """è¾æ›¸å†…ã®ç”»åƒãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰é¡ä¼¼åº¦ä¸Šä½Kä»¶ã‚’æ¤œç´¢"""
    paths = list(features_dict.keys())
    features = np.array(list(features_dict.values()))
    sims = cosine_similarity([query_feature], features)[0]
    top_indices = np.argsort(sims)[::-1][:top_k]
    results = [(paths[i], sims[i]) for i in top_indices]
    return results

# ======== Streamlit UI ========
st.set_page_config(page_title="ãã‚‰ã‚‚ã‚ˆã†AI", page_icon="ğŸŒ¤ï¸", layout="centered")
st.title("ğŸŒ¤ï¸ ãã‚‰ã‚‚ã‚ˆã†AI")
st.caption("ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€ç©ºã‚’è¡¨ã™æ—¥æœ¬èªã¨æ“¬æ…‹èªã‚’AIãŒææ¡ˆã—ã€ä¼¼ãŸç©ºã®å†™çœŸã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")

# é¡ä¼¼ç”»åƒãƒ•ã‚©ãƒ«ãƒ€
image_folder = "images"
os.makedirs(image_folder, exist_ok=True)
image_paths = glob.glob(os.path.join(image_folder, "*.jpg")) + \
              glob.glob(os.path.join(image_folder, "*.jpeg")) + \
              glob.glob(os.path.join(image_folder, "*.png")) + \
              glob.glob(os.path.join(image_folder, "*.heic"))

# æ—¢å­˜ç”»åƒã®ç‰¹å¾´é‡ã‚’äº‹å‰è¨ˆç®—
features_dict = {}
if image_paths:
    with st.spinner("æ—¢å­˜ã®ç”»åƒã‚’è§£æä¸­..."):
        for path in image_paths:
            try:
                features_dict[path] = get_image_feature(path)
            except Exception as e:
                st.warning(f"{path} ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

uploaded_file = st.file_uploader("ç©ºã®å†™çœŸã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆJPEG/PNG/HEICï¼‰", type=["jpg", "jpeg", "png", "heic"])

if uploaded_file:
    clip_model, preprocess = load_clip_model()
    st.image(uploaded_file, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸç”»åƒ", use_container_width=True)
    image_bytes = uploaded_file.read()

    # --- Geminiã«ã‚ˆã‚‹è§£æ ---
    with st.spinner("AIãŒç©ºã‚’åˆ†æã—ã¦ã„ã¾ã™â€¦ ğŸ”"):
        result_text = describe_image_with_gemini(client, image_bytes)

    st.subheader("ğŸ§­ AIã®å‡ºåŠ›çµæœ")
    st.write(result_text)

    # --- CLIPã«ã‚ˆã‚‹é¡ä¼¼æ¤œç´¢ ---
    if features_dict:
        query_feature = get_image_feature(uploaded_file)
        with st.spinner("é¡ä¼¼ç”»åƒã‚’æ¤œç´¢ä¸­..."):
            top_results = find_top_similar(query_feature, features_dict, top_k=3)

        st.subheader("ğŸ” é¡ä¼¼ã—ã¦ã„ã‚‹ç©ºã®å†™çœŸï¼ˆä¸Šä½3æšï¼‰")
        cols = st.columns(3)
        for col, (path, score) in zip(cols, top_results):
            col.image(path, caption=f"é¡ä¼¼åº¦ï¼š{score:.3f}", use_container_width=True)
    else:
        st.info("æ¯”è¼ƒå¯¾è±¡ã¨ãªã‚‹ç”»åƒãŒãƒ•ã‚©ãƒ«ãƒ€å†…ã«ã‚ã‚Šã¾ã›ã‚“ã€‚`images/` ãƒ•ã‚©ãƒ«ãƒ€ã«ç©ºã®å†™çœŸã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")

st.markdown("---")
st.caption("Gemini API + CLIPã«ã‚ˆã‚Šã€ç©ºã®æ—¥æœ¬èªè¡¨ç¾ã¨é¡ä¼¼ç©ºæ¨¡æ§˜ã®æ¤œç´¢ã‚’è¡Œã„ã¾ã™ã€‚")
